name: "03 - Participantes (scrape + process)"

on:
  workflow_run:
    workflows: ["02 - INFO desde 01events"]
    types: [completed]
  workflow_dispatch:
    inputs:
      LIMIT_EVENTS:
        description: "Máx. eventos a scrapear (0 = sin límite)"
        required: false
        default: "0"
      LIMIT_PARTICIPANTS:
        description: "Máx. participantes por evento (0 = sin límite)"
        required: false
        default: "0"
      MAX_EVENT_SECONDS:
        description: "Tiempo máx por evento (seg)"
        required: false
        default: "900"

permissions:
  contents: read
  actions: read

concurrency:
  group: participantes-03
  cancel-in-progress: true

jobs:
  run_and_upload:
    if: ${{ github.event_name == 'workflow_dispatch' || (github.event_name == 'workflow_run' && github.event.workflow_run.conclusion == 'success' && github.event.workflow_run.name == '02 - INFO desde 01events') }}
    runs-on: ubuntu-latest
    timeout-minutes: 120

    env:
      TZ: Europe/Madrid
      OUT_DIR: ./output
      FLOW_EMAIL: ${{ secrets.FLOW_EMAIL }}
      FLOW_PASS:  ${{ secrets.FLOW_PASS }}
      HEADLESS: "true"
      INCOGNITO: "true"
      FILE_PREFIX: "03"
      # Por defecto sin límite (0). Si lo lanzas a mano puedes ajustar en inputs.
      LIMIT_EVENTS: ${{ inputs.LIMIT_EVENTS || '0' }}
      LIMIT_PARTICIPANTS: ${{ inputs.LIMIT_PARTICIPANTS || '0' }}
      # Limita cuánto tiempo puede tragarse cada evento antes de pasar al siguiente.
      MAX_EVENT_SECONDS: ${{ inputs.MAX_EVENT_SECONDS || '600' }} # corta un evento muy lento
      # Ralentiza un poco pero más estable en CI
      # Ritmos
      SLOW_MIN_S=1.2
      SLOW_MAX_S=3.0
      SCROLL_WAIT_S=2.5
      MAX_SCROLLS=10
      PER_PART_TIMEOUT_S=8
      RENDER_POLL_S=0.35
      CLICK_RETRIES=2

    steps:
      - uses: actions/checkout@v4

      - name: "Debug trigger"
        run: |
          echo "event_name=${{ github.event_name }}"
          if [ "${{ github.event_name }}" = "workflow_run" ]; then
            echo "prev workflow: ${{ github.event.workflow_run.name }}"
            echo "prev conclusion: ${{ github.event.workflow_run.conclusion }}"
          fi
          echo "LIMIT_EVENTS=${LIMIT_EVENTS} LIMIT_PARTICIPANTS=${LIMIT_PARTICIPANTS} MAX_EVENT_SECONDS=${MAX_EVENT_SECONDS}"

      - uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: pip
          cache-dependency-path: requirements.txt

      - name: "Instalar dependencias"
        run: |
          set -euo pipefail
          python -m pip install --upgrade pip setuptools wheel
          if [ -f requirements.txt ]; then
            pip install -r requirements.txt
          else
            pip install selenium webdriver-manager beautifulsoup4 python-dotenv pandas python-dateutil numpy
          fi

      - name: "Instalar Google Chrome"
        uses: browser-actions/setup-chrome@v1

      # --- SCRAPE (tolerante a timeout) ---
      - name: "Scrape (máx 40 min, continúa aunque expire)"
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p "$OUT_DIR"
          SCRIPT="./03_eventosproxParticipantes.py"
          if [ ! -f "$SCRIPT" ]; then
            echo "::error::No se encontró $SCRIPT"; exit 1
          fi
          # Si excede, seguimos igualmente a process con lo que haya dejado en ./output
          if ! timeout 40m python "$SCRIPT" scrape; then
            echo "::warning::Scrape llegó a timeout; continuo a process con los CSV existentes."
            pkill -9 -f chrome || true
            pkill -9 -f chromedriver || true
          fi

      # --- PROCESS (rápido; usa el CSV más reciente) ---
      - name: "Process (máx 10 min)"
        shell: bash
        run: |
          set -euo pipefail
          python "./03_eventosproxParticipantes.py" process

      - name: "Listado de outputs"
        run: |
          echo "Contenido de $OUT_DIR:"
          ls -la "$OUT_DIR" || true
          echo "Coincidencias previstas:"
          ls -1 ./output/*events_*.csv 2>/dev/null || true
          ls -1 ./output/*participantes_*.csv 2>/dev/null || true
          ls -1 ./output/participantes.json 2>/dev/null || true
          ls -1 ./output/participantes_*.json 2>/dev/null || true
          ls -1 ./output/participantes_procesado_*.csv 2>/dev/null || true
          ls -1 ./output/*progress_*.json 2>/dev/null || true

      - name: "Assert salida procesada"
        run: |
          set -euo pipefail
          shopt -s nullglob
          processed=( ./output/participantes_procesado_*.csv ./output/participantes.json )
          echo "Procesados: ${processed[*]:-<ninguno>}"
          if [ ${#processed[@]} -eq 0 ]; then
            echo "::error::No hay archivo procesado. Revisa límites/timeout."; exit 1
          fi

      - name: "Subir artefactos (JSON+CSV)"
        uses: actions/upload-artifact@v4
        with:
          name: a03-participants-processed
          path: |
            ./output/*events_*.csv
            ./output/*participantes_*.csv
            ./output/participantes.json
            ./output/participantes_*.json
            ./output/participantes_procesado_*.csv
            ./output/*progress_*.json
          if-no-files-found: error
          retention-days: 5

      # (Opcional) Sube a FTP como en el 01; puedes quitar este bloque si no lo necesitas.
      - name: "Install lftp"
        run: sudo apt-get update && sudo apt-get install -y lftp

      - name: "(FTPS) Upload últimos JSON/CSV de 03"
        env:
          FTP_SERVER:     ${{ secrets.FTP_SERVER }}
          FTP_USERNAME:   ${{ secrets.FTP_USERNAME }}
          FTP_PASSWORD:   ${{ secrets.FTP_PASSWORD }}
          FTP_REMOTE_DIR: ${{ secrets.FTP_REMOTE_DIR }}
        shell: bash
        run: |
          set -euo pipefail
          DEST_DIR="$(printf "%s/Competiciones/ListadoEventos/Workflows/03" "${FTP_REMOTE_DIR%/}")"
          echo "DEST_DIR calculado: $DEST_DIR"
          lftp -u "${FTP_USERNAME},${FTP_PASSWORD}" "${FTP_SERVER}" -e " \
            set cmd:fail-exit true; \
            set net:timeout 25; \
            set net:max-retries 1; \
            set net:persist-retries 0; \
            set ftp:ssl-force true; \
            set ftp:ssl-protect-data true; \
            set ftp:passive-mode true; \
            set ftp:prefer-epsv false; \
            set ssl:verify-certificate no; \
            cd '${FTP_REMOTE_DIR}' || cd '/${FTP_REMOTE_DIR}'; \
            mkdir -f Competiciones; cd Competiciones; \
            mkdir -f ListadoEventos; cd ListadoEventos; \
            mkdir -f Workflows; cd Workflows; \
            mkdir -f 03; cd 03; \
            mirror -Rnv --ignore-time --include-glob '*events_*.csv' ./output . || true; \
            mirror -Rnv --ignore-time --include-glob '*participantes_*.csv' ./output . || true; \
            mirror -Rnv --ignore-time --include-glob 'participantes*.json' ./output . || true; \
            mirror -Rnv --ignore-time --include-glob 'participantes_procesado_*.csv' ./output . || true; \
            echo 'Contenido en destino 03:'; pwd; cls -l; \
            bye"
