name: 03 Participantes (scrape + process)

on:
  schedule:
    - cron: '3 4 * * *'
  workflow_dispatch: {}

jobs:
  run_and_upload:
    runs-on: ubuntu-latest
    env:
      TZ: Europe/Madrid
      OUT_DIR: ./output
      FLOW_EMAIL: ${{ secrets.FLOW_EMAIL }}
      FLOW_PASS: ${{ secrets.FLOW_PASS }}
      HEADLESS: "true"
      INCOGNITO: "true"
      FILE_PREFIX: "03"
      LIMIT_EVENTS: "0"
      LIMIT_PARTICIPANTS: "0"

    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: pip
          cache-dependency-path: requirements.txt

      - name: Instalar dependencias
        shell: bash
        run: |
          set -euo pipefail
          python -m pip install --upgrade pip
          if [ -f requirements.txt ]; then
            pip install -r requirements.txt
          else
            pip install selenium webdriver-manager beautifulsoup4 python-dotenv pandas python-dateutil numpy
          fi

      - name: "Ejecutar 03 (all: scrape + process)"
        shell: bash
        run: |
          set -euo pipefail
          python "./03_eventosproxParticipantes.py" all

      - name: Listado de outputs
        shell: bash
        run: |
          echo "Contenido de $OUT_DIR:"
          ls -la "$OUT_DIR" || true

      - name: Upload processed participants (JSON+CSV)
        uses: actions/upload-artifact@v4
        with:
          name: a03-participants-processed
          path: |
            ./output/03events_*.csv
            ./output/03participantes_*.csv
            ./output/participantes.json
            ./output/participantes_*.json
            ./output/participantes_procesado_*.csv
            ./output/03progress_*.json
          if-no-files-found: warn
